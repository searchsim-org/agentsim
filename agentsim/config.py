"""Configuration management for AgentSim"""

import os
from pathlib import Path
from typing import Optional, List, Dict
from dotenv import load_dotenv

# Load .env file if it exists
env_path = Path(__file__).parent.parent / ".env"
if env_path.exists():
    load_dotenv(env_path)


class Config:
    """Global configuration from environment variables"""
    
    # ============================================
    # LLM Provider API Keys
    # ============================================
    OPENAI_API_KEY: Optional[str] = os.getenv("OPENAI_API_KEY")
    OPENAI_ORG_ID: Optional[str] = os.getenv("OPENAI_ORG_ID")
    
    ANTHROPIC_API_KEY: Optional[str] = os.getenv("ANTHROPIC_API_KEY")
    
    GOOGLE_API_KEY: Optional[str] = os.getenv("GOOGLE_API_KEY")
    GOOGLE_PROJECT_ID: Optional[str] = os.getenv("GOOGLE_PROJECT_ID")
    
    MISTRAL_API_KEY: Optional[str] = os.getenv("MISTRAL_API_KEY")
    COHERE_API_KEY: Optional[str] = os.getenv("COHERE_API_KEY")
    TOGETHER_API_KEY: Optional[str] = os.getenv("TOGETHER_API_KEY")
    
    # Custom endpoints
    CUSTOM_LLM_ENDPOINT: Optional[str] = os.getenv("CUSTOM_LLM_ENDPOINT")
    CUSTOM_LLM_API_KEY: Optional[str] = os.getenv("CUSTOM_LLM_API_KEY")
    
    # Ollama
    OLLAMA_ENDPOINT: str = os.getenv("OLLAMA_ENDPOINT", "http://localhost:11434")
    OLLAMA_ENABLED: bool = os.getenv("OLLAMA_ENABLED", "false").lower() == "true"
    
    # ============================================
    # Default Models
    # ============================================
    TEACHER_MODELS: List[str] = [m.strip() for m in os.getenv("TEACHER_MODELS", "gpt-4o").split(",") if m.strip()]
    TEACHER_TEMPERATURE: float = float(os.getenv("TEACHER_TEMPERATURE", "0.7"))
    
    CONSULTANT_MODELS: List[str] = [m.strip() for m in os.getenv("CONSULTANT_MODELS", "").split(",") if m.strip()]
    CONSULTANT_TEMPERATURE: float = float(os.getenv("CONSULTANT_TEMPERATURE", "0.7"))
    
    VERIFIER_MODEL: str = os.getenv("VERIFIER_MODEL", "gpt-4o-mini")
    VERIFIER_TEMPERATURE: float = float(os.getenv("VERIFIER_TEMPERATURE", "0.1"))
    
    # Embeddings
    LOCAL_EMBEDDING_MODEL: str = os.getenv("LOCAL_EMBEDDING_MODEL", "sentence-transformers/all-MiniLM-L6-v2")
    
    # ============================================
    # Retrieval
    # ============================================
    OPENSEARCH_HOST: str = os.getenv("OPENSEARCH_HOST", "localhost")
    OPENSEARCH_PORT: int = int(os.getenv("OPENSEARCH_PORT", "9200"))
    OPENSEARCH_INDEX: str = os.getenv("OPENSEARCH_INDEX", "documents")
    OPENSEARCH_USER: Optional[str] = os.getenv("OPENSEARCH_USER")
    OPENSEARCH_PASSWORD: Optional[str] = os.getenv("OPENSEARCH_PASSWORD")
    OPENSEARCH_USE_SSL: bool = os.getenv("OPENSEARCH_USE_SSL", "false").lower() == "true"
    
    VECTOR_SEARCH_ENABLED: bool = os.getenv("VECTOR_SEARCH_ENABLED", "false").lower() == "true"
    VECTOR_SEARCH_ENDPOINT: Optional[str] = os.getenv("VECTOR_SEARCH_ENDPOINT")
    
    # ChatNoir (primary retrieval)
    CHATNOIR_ENABLED: bool = os.getenv("CHATNOIR_ENABLED", "true").lower() == "true"
    CHATNOIR_API_KEY: Optional[str] = os.getenv("CHATNOIR_API_KEY")
    CHATNOIR_BASE_URL: str = os.getenv("CHATNOIR_BASE_URL", "https://www.chatnoir.eu/api/v1")
    CHATNOIR_DEFAULT_CORPUS: str = os.getenv("CHATNOIR_DEFAULT_CORPUS", "cw12")
    
    # ============================================
    # Simulation
    # ============================================
    MAX_ITERATIONS: int = int(os.getenv("MAX_ITERATIONS", "5"))
    SIMILARITY_THRESHOLD: float = float(os.getenv("SIMILARITY_THRESHOLD", "0.6"))
    SIMILARITY_METRIC: str = os.getenv("SIMILARITY_METRIC", "embedding_cosine")
    
    OUTPUT_DIR: str = os.getenv("OUTPUT_DIR", "./data/simulation_output")
    
    # ============================================
    # Advanced LLM Settings
    # ============================================
    LLM_TIMEOUT: int = int(os.getenv("LLM_TIMEOUT", "60"))
    LLM_MAX_RETRIES: int = int(os.getenv("LLM_MAX_RETRIES", "3"))
    LLM_MAX_TOKENS: int = int(os.getenv("LLM_MAX_TOKENS", "4096"))
    
    @classmethod
    def get_provider_from_model_id(cls, model_id: str) -> str:
        """Detect provider from model ID"""
        model_lower = model_id.lower()
        
        # Check for custom/ollama prefixes first
        if model_id.startswith("custom/"):
            return "custom"
        elif model_id.startswith("ollama/"):
            return "ollama"
        elif any(x in model_lower for x in ["gpt", "openai", "o1", "davinci", "turbo"]):
            return "openai"
        elif any(x in model_lower for x in ["claude", "anthropic"]):
            return "anthropic"
        elif any(x in model_lower for x in ["gemini", "palm", "bison"]):
            return "google"
        elif "mistral" in model_lower:
            return "mistral"
        elif "cohere" in model_lower or "command" in model_lower:
            return "cohere"
        elif "together" in model_lower:
            return "together"
        else:
            # Default to openai for unknown models
            return "openai"
    
    @classmethod
    def get_api_key_for_provider(cls, provider: str) -> Optional[str]:
        """Get API key for a specific provider"""
        provider_keys: Dict[str, Optional[str]] = {
            "openai": cls.OPENAI_API_KEY,
            "anthropic": cls.ANTHROPIC_API_KEY,
            "google": cls.GOOGLE_API_KEY,
            "mistral": cls.MISTRAL_API_KEY,
            "cohere": cls.COHERE_API_KEY,
            "together": cls.TOGETHER_API_KEY,
            "custom": cls.CUSTOM_LLM_API_KEY,
            "ollama": None,  # Ollama doesn't require API key by default
        }
        return provider_keys.get(provider.lower())
    
    @classmethod
    def get_model_api_key(cls, model_id: str) -> Optional[str]:
        """Get API key for a specific model ID"""
        provider = cls.get_provider_from_model_id(model_id)
        return cls.get_api_key_for_provider(provider)
    
    @classmethod
    def get_provider_config(cls, provider: str) -> Dict[str, any]:
        """Get additional provider-specific configuration"""
        configs = {
            "openai": {
                "api_key": cls.OPENAI_API_KEY,
                "organization": cls.OPENAI_ORG_ID,
            },
            "google": {
                "api_key": cls.GOOGLE_API_KEY,
                "project_id": cls.GOOGLE_PROJECT_ID,
            },
            "custom": {
                "api_key": cls.CUSTOM_LLM_API_KEY,
                "endpoint": cls.CUSTOM_LLM_ENDPOINT,
            },
            "ollama": {
                "endpoint": cls.OLLAMA_ENDPOINT,
                "enabled": cls.OLLAMA_ENABLED,
            },
        }
        return configs.get(provider.lower(), {})


config = Config()

